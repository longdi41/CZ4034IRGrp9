{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c469dcb1-4c19-44c1-adc1-0e83f5114b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import nltk\n",
    "import re \n",
    "import os \n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import pickle\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "df1 = pd.read_csv('manual.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a6536b-138d-455d-8cf6-85ce5a835a88",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 0. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8a09b1-3d1d-4e97-818f-9394c0c7a2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/zhang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/zhang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/zhang/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/zhang/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "416502d247c742cf941d47876baa12e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b88dde89342a4e56a399829302d26e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0a8e9caa7040babd5341986e84af57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "def clean(text):\n",
    "    text = re.sub('[^A-Za-z]+', ' ', text)\n",
    "    return text\n",
    "df1['cleaned'] = df1['Text'].apply(clean)\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "# POS tagger dictionary\n",
    "pos_dict = {'J':wordnet.ADJ, 'V':wordnet.VERB, 'N':wordnet.NOUN, 'R':wordnet.ADV}\n",
    "def token_stop_pos(text):\n",
    "    tags = pos_tag(word_tokenize(text))\n",
    "    newlist = []\n",
    "    for word, tag in tags:\n",
    "        if word.lower() not in set(stopwords.words('english')):\n",
    "            newlist.append(tuple([word, pos_dict.get(tag[0])]))\n",
    "    return newlist\n",
    "\n",
    "df1['tagged'] = df1['cleaned'].progress_apply(token_stop_pos)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize(pos_data):\n",
    "    lemma_rew = \" \"\n",
    "    for word, pos in pos_data:\n",
    "        if not pos:\n",
    "            lemma = word\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "        else:\n",
    "            lemma = wordnet_lemmatizer.lemmatize(word, pos=pos)\n",
    "            lemma_rew = lemma_rew + \" \" + lemma\n",
    "    return lemma_rew\n",
    "\n",
    "df1['lemma'] = df1['tagged'].progress_apply(lemmatize)\n",
    "\n",
    "from nltk.stem import LancasterStemmer\n",
    "lancaster = LancasterStemmer()\n",
    "def stemmize(tagged):\n",
    "    stemmed = ''\n",
    "    for word, _ in tagged:\n",
    "        stemmed = stemmed +' '+lancaster.stem(word)\n",
    "    return stemmed.strip()\n",
    "\n",
    "df1['stemmed'] = df1['tagged'].progress_apply(stemmize)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d9ca55f-e1c0-405e-93b2-a03c868627dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@lindseyhilsum Ms Hilsum sad the atrocities committed across Ukraine and the war crimes. It appears war crimes are only committed by Russia in Aleppo and now on Ukraine. Where is your war crimes coverage in Iraq, Afghanistan also in Syria when west were arming the resistance to remove Assad?'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e40f97-2ff6-4739-a006-58d92c212acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(536, 664)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neutral_text = list(df1[df1.label==0]['stemmed'])\n",
    "neutral_label = [0]*len(neutral_text)\n",
    "opinioned_text = list(df1[df1.label!=0]['stemmed'])\n",
    "opinioned_label = [1]*len(opinioned_text)\n",
    "len(neutral_text),len(opinioned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b02c1ed-02bc-4d23-84dd-5352a858eae2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, 352)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_text = list(df1[df1.label==-1]['stemmed'])\n",
    "neg_label = [0]*len(neg_text)\n",
    "pos_text = list(df1[df1.label==1]['stemmed'])\n",
    "pos_label = [1]*len(pos_text)\n",
    "len(pos_text),len(neg_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffa30f24-9fe0-47a4-9cde-36c55fa9cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "subject_text = neutral_text+opinioned_text\n",
    "subject_label = neutral_label+opinioned_label\n",
    "\n",
    "polarity_text = pos_text+neg_text\n",
    "polarity_label = pos_label+neg_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f95dcbc-272c-4339-9ec0-a2d39e45e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b53452b9-28a5-4668-8884-b5ca49e713cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(polarity_text)\n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(text_tf, polarity_label, test_size=0.2, random_state=114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d75159b-f7e7-492f-833c-8202222cb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf-pkl/polarity_text.pkl','wb') as f:\n",
    "    pickle.dump(tf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37e9d816-9b85-40c5-b0b7-635c075a9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(subject_text)\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(text_tf, subject_label, test_size=0.2, random_state=114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46ba7120-3271-489b-928e-49c23c765e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tf-pkl/subject_text.pkl','wb') as f:\n",
    "    pickle.dump(tf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27926030-7d1a-4497-83b8-5e1691e7b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p = X_train_p.toarray()\n",
    "X_test_p = X_test_p.toarray()\n",
    "X_train_s = X_train_s.toarray()\n",
    "X_test_s = X_test_s.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "301a820c-9f65-4201-ab7e-9375fc6d6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141414ec-9d65-439c-a140-c4a9298a93f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Subjectivity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44cd4ba2-506a-46a8-8a91-b8fea3541b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'n_neighbors':list(range(1,20,2))+list(range(20,105,5)),\n",
    "    'weights':['uniform', 'distance']\n",
    "}\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "logistic_params = {\n",
    "    'penalty':['l1','l2','elasticnet','none']\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_params = {\n",
    "    'n_estimators':list(range(2,21,2)),\n",
    "    'criterion':['gini','entropy'],\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc_params = {\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'splitter':['best','random']\n",
    "}\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "rbf_svc = SVC()\n",
    "rbf_svc_params = {\n",
    "    'C':[0.01,0.1,1,10]\n",
    "}\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "lin_svc = SVC()\n",
    "lin_svc_params = {\n",
    "    'kernel':['linear'],\n",
    "    'C':[0.01,0.1,1,10]\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb_params = {\n",
    "    'alpha':[0,0.01,0.1,1,10]\n",
    "}\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc_params = {\n",
    "    'loss':['deviance','exponential'],\n",
    "    'learning_rate':[0.0001,0.001,0.01,0.1],\n",
    "    'n_estimators':[2,10,50,100,200],\n",
    "    'criterion':['friedman_mse','squared_error','mse','mae']\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "abc_params={\n",
    "    'learning_rate':[0.0001,0.001,0.01,0.1],\n",
    "    'n_estimators':[2,10,50,100,200],\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_params = {\n",
    "    'solver':['svd','lsqr','eigen']\n",
    "}\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda_params = {\n",
    "    'reg_param':[0,0.001,0.001,0.01,0.1]\n",
    "}\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier()\n",
    "nn_params = {\n",
    "    'alpha':[0.01,0.1,1],\n",
    "    'max_iter':[2000]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'knn':knn,\n",
    "    'logistic_regression':logistic,\n",
    "    'random_forest':rfc,\n",
    "    'decision_tree':dtc,\n",
    "    'rbf_svc':rbf_svc,\n",
    "    'linear_svc':lin_svc,\n",
    "    'naive_bayes':mnb,\n",
    "    'adaboost':abc,\n",
    "    'linear_discriminant':lda,\n",
    "    'quadratic_discriminant':qda,\n",
    "    'neural_network':nn\n",
    "    \n",
    "    \n",
    "}\n",
    "params = {\n",
    "    'knn':knn_params,\n",
    "    'logistic_regression':logistic_params,\n",
    "    'random_forest':rfc_params,\n",
    "    'decision_tree':dtc_params,\n",
    "    'rbf_svc':rbf_svc_params,\n",
    "    'linear_svc':lin_svc_params,\n",
    "    'naive_bayes':mnb_params,\n",
    "    'adaboost':abc_params,\n",
    "    'linear_discriminant':lda_params,\n",
    "    'quadratic_discriminant':qda_params,\n",
    "    'neural_network':nn_params\n",
    "}\n",
    "\n",
    "best={}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "215eb980-2726-4ba0-b2ba-ef73eff92012",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5802279d2b914a71b5b6afb4c3cfbf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n",
      "random_forest\n",
      "decision_tree\n",
      "rbf_svc\n",
      "linear_svc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes\n",
      "adaboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 558, in fit\n",
      "    self._solve_eigen(X, y,\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 419, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 2 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 558, in fit\n",
      "    self._solve_eigen(X, y,\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 419, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 4 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 558, in fit\n",
      "    self._solve_eigen(X, y,\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 419, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 3 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 558, in fit\n",
      "    self._solve_eigen(X, y,\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 419, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 5 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 558, in fit\n",
      "    self._solve_eigen(X, y,\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 419, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 1 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_discriminant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quadratic_discriminant\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'MLPClassifier' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/jk/qnh6g1s13mzf5hykcng3_3z40000gn/T/ipykernel_29121/3052909095.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mgcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mbest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, estimator, param_grid, scoring, n_jobs, refit, cv, verbose, pre_dispatch, error_score, return_train_score)\u001b[0m\n\u001b[1;32m   1290\u001b[0m             return_train_score=return_train_score)\n\u001b[1;32m   1291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m         \u001b[0m_check_param_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_check_param_grid\u001b[0;34m(param_grid)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'MLPClassifier' object is not iterable"
     ]
    }
   ],
   "source": [
    "for k in tqdm(classifiers):\n",
    "    gcv = GridSearchCV(estimator=classifiers[k], param_grid=params[k], n_jobs=-1)\n",
    "    gcv.fit(X_train_s, y_train_s)\n",
    "    best[k]=gcv.best_estimator_\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "58bc37c7-9add-48e7-a08b-b4b8b6ee5881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb876a3ad5ef4d62bc54bdaa1e39b496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_dict = {}\n",
    "for k in tqdm(best):\n",
    "    with open(f'sklearn-pkl/subjectivity/{k}.pkl','wb') as f:\n",
    "        pickle.dump(best[k],f)\n",
    "    y_pred_s = best[k].predict(X_test_s)\n",
    "    score_dict[k]={\n",
    "        'accuracy':accuracy_score(y_pred_s,y_test_s),\n",
    "        'precision':precision_score(y_pred_s,y_test_s),\n",
    "        'recall':recall_score(y_pred_s,y_test_s),\n",
    "        'f1':f1_score(y_pred_s,y_test_s),\n",
    "        'Details':str(best[k])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "508423a3-12fc-4a6b-b6a7-eb14a0f09851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.794326</td>\n",
       "      <td>0.802867</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_regression</th>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.823944</td>\n",
       "      <td>0.835714</td>\n",
       "      <td>LogisticRegression(penalty='none')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.702899</td>\n",
       "      <td>0.889908</td>\n",
       "      <td>0.785425</td>\n",
       "      <td>RandomForestClassifier(n_estimators=20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.7125</td>\n",
       "      <td>0.637681</td>\n",
       "      <td>0.82243</td>\n",
       "      <td>0.718367</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf_svc</th>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.862319</td>\n",
       "      <td>0.826389</td>\n",
       "      <td>0.843972</td>\n",
       "      <td>SVC(C=10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_svc</th>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.84058</td>\n",
       "      <td>0.834532</td>\n",
       "      <td>0.837545</td>\n",
       "      <td>SVC(C=10, kernel='linear')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.934783</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.832258</td>\n",
       "      <td>MultinomialNB(alpha=0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.746377</td>\n",
       "      <td>0.858333</td>\n",
       "      <td>0.79845</td>\n",
       "      <td>AdaBoostClassifier(learning_rate=0.1, n_estima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_discriminant</th>\n",
       "      <td>0.629167</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.658065</td>\n",
       "      <td>0.696246</td>\n",
       "      <td>LinearDiscriminantAnalysis()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quadratic_discriminant</th>\n",
       "      <td>0.575</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(reg_param=0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_network</th>\n",
       "      <td>0.825</td>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.848921</td>\n",
       "      <td>MLPClassifier(alpha=0.1, max_iter=2000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy precision    recall        f1  \\\n",
       "knn                     0.770833  0.811594  0.794326  0.802867   \n",
       "logistic_regression     0.808333  0.847826  0.823944  0.835714   \n",
       "random_forest           0.779167  0.702899  0.889908  0.785425   \n",
       "decision_tree             0.7125  0.637681   0.82243  0.718367   \n",
       "rbf_svc                 0.816667  0.862319  0.826389  0.843972   \n",
       "linear_svc                0.8125   0.84058  0.834532  0.837545   \n",
       "naive_bayes             0.783333  0.934783      0.75  0.832258   \n",
       "adaboost                0.783333  0.746377  0.858333   0.79845   \n",
       "linear_discriminant     0.629167   0.73913  0.658065  0.696246   \n",
       "quadratic_discriminant     0.575       1.0     0.575  0.730159   \n",
       "neural_network             0.825  0.855072  0.842857  0.848921   \n",
       "\n",
       "                                                                  Details  \n",
       "knn                                  KNeighborsClassifier(n_neighbors=20)  \n",
       "logistic_regression                    LogisticRegression(penalty='none')  \n",
       "random_forest                     RandomForestClassifier(n_estimators=20)  \n",
       "decision_tree           DecisionTreeClassifier(criterion='entropy', sp...  \n",
       "rbf_svc                                                         SVC(C=10)  \n",
       "linear_svc                                     SVC(C=10, kernel='linear')  \n",
       "naive_bayes                                      MultinomialNB(alpha=0.1)  \n",
       "adaboost                AdaBoostClassifier(learning_rate=0.1, n_estima...  \n",
       "linear_discriminant                          LinearDiscriminantAnalysis()  \n",
       "quadratic_discriminant     QuadraticDiscriminantAnalysis(reg_param=0.001)  \n",
       "neural_network                    MLPClassifier(alpha=0.1, max_iter=2000)  "
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subjectivity_result = pd.DataFrame(score_dict).T\n",
    "subjectivity_result.to_csv('subjectivity_result.csv',index=False)\n",
    "subjectivity_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "791ea469-6eaa-4095-b46a-60fb500614a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(alpha=0.1, max_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a86c3cb8-2c26-4eb1-8c4b-4084220a8532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(alpha=0.1, max_iter=2000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_s, y_train_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "466418e7-59c7-4cff-b066-3bb54f0fd0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(subject_text)\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(text_tf, subject_label, test_size=0.2, random_state=114514)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84c4908c-915b-4a91-bb57-d420cb5234b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'check anarchotok video tiktok https co kjyliffxfx ukrain russiaukraineconflict'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject_text[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "255d81da-bff3-49d5-8a5c-f2172229a436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test_s)\n",
    "# tf.transform(['hi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e312e0f-4faf-41d8-885a-44309b6dbef5",
   "metadata": {},
   "source": [
    "## 2. Polarity Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "560f677e-419f-47b9-a016-89b98b4e53de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {\n",
    "    'n_neighbors':list(range(1,20,2))+list(range(20,105,5)),\n",
    "    'weights':['uniform', 'distance']\n",
    "}\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "logistic = LogisticRegression()\n",
    "logistic_params = {\n",
    "    'penalty':['l1','l2','elasticnet','none']\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "rfc_params = {\n",
    "    'n_estimators':list(range(2,21,2)),\n",
    "    'criterion':['gini','entropy'],\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "dtc_params = {\n",
    "    'criterion':['gini', 'entropy'],\n",
    "    'splitter':['best','random']\n",
    "}\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "rbf_svc = SVC()\n",
    "rbf_svc_params = {\n",
    "    'C':[0.01,0.1,1,10]\n",
    "}\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "lin_svc = SVC()\n",
    "lin_svc_params = {\n",
    "    'kernel':['linear'],\n",
    "    'C':[0.01,0.1,1,10]\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb_params = {\n",
    "    'alpha':[0,0.01,0.1,1,10]\n",
    "}\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbc = GradientBoostingClassifier()\n",
    "gbc_params = {\n",
    "    'loss':['deviance','exponential'],\n",
    "    'learning_rate':[0.0001,0.001,0.01,0.1],\n",
    "    'n_estimators':[2,10,50,100,200],\n",
    "    'criterion':['friedman_mse','squared_error','mse','mae']\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.ensemble import  AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "abc_params={\n",
    "    'learning_rate':[0.0001,0.001,0.01,0.1],\n",
    "    'n_estimators':[2,10,50,100,200],\n",
    "}\n",
    "\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda_params = {\n",
    "    'solver':['svd','lsqr','eigen']\n",
    "}\n",
    "\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "qda_params = {\n",
    "    'reg_param':[0,0.001,0.001,0.01,0.1]\n",
    "}\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn = MLPClassifier()\n",
    "nn_params = {\n",
    "    'alpha':[0.01,0.1,1],\n",
    "    'max_iter':[2000]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "    'knn':knn,\n",
    "    'logistic_regression':logistic,\n",
    "    'random_forest':rfc,\n",
    "    'decision_tree':dtc,\n",
    "    'rbf_svc':rbf_svc,\n",
    "    'linear_svc':lin_svc,\n",
    "    'naive_bayes':mnb,\n",
    "    'adaboost':abc,\n",
    "    'linear_discriminant':lda,\n",
    "    'quadratic_discriminant':qda,\n",
    "    'neural_network':nn\n",
    "    \n",
    "    \n",
    "}\n",
    "params = {\n",
    "    'knn':knn_params,\n",
    "    'logistic_regression':logistic_params,\n",
    "    'random_forest':rfc_params,\n",
    "    'decision_tree':dtc_params,\n",
    "    'rbf_svc':rbf_svc_params,\n",
    "    'linear_svc':lin_svc_params,\n",
    "    'naive_bayes':mnb_params,\n",
    "    'adaboost':abc_params,\n",
    "    'linear_discriminant':lda_params,\n",
    "    'quadratic_discriminant':qda_params,\n",
    "    'neural_network':nn_params\n",
    "}\n",
    "\n",
    "best={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "a8a6afcb-288e-4407-b6cb-1c25505a9e5c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14813d79ca754ae788e3be1a6ce452e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic_regression\n",
      "random_forest\n",
      "decision_tree\n",
      "rbf_svc\n",
      "linear_svc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/naive_bayes.py:508: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  warnings.warn('alpha too small will result in numeric errors, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive_bayes\n",
      "adaboost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 558, in fit\n",
      "    self._solve_eigen(X, y,\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 419, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 7 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 558, in fit\n",
      "    self._solve_eigen(X, y,\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 419, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 7 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 558, in fit\n",
      "    self._solve_eigen(X, y,\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 419, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 1 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 558, in fit\n",
      "    self._solve_eigen(X, y,\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 419, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 6 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 558, in fit\n",
      "    self._solve_eigen(X, y,\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py\", line 419, in _solve_eigen\n",
      "    evals, evecs = linalg.eigh(Sb, Sw)\n",
      "  File \"/opt/homebrew/anaconda3/lib/python3.9/site-packages/scipy/linalg/decomp.py\", line 578, in eigh\n",
      "    raise LinAlgError('The leading minor of order {} of B is not '\n",
      "numpy.linalg.LinAlgError: The leading minor of order 3 of B is not positive definite. The factorization of B could not be completed and no eigenvalues or eigenvectors were computed.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_discriminant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n",
      "/opt/homebrew/anaconda3/lib/python3.9/site-packages/sklearn/discriminant_analysis.py:808: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quadratic_discriminant\n",
      "neural_network\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(classifiers):\n",
    "    gcv = GridSearchCV(estimator=classifiers[k], param_grid=params[k], n_jobs=-1)\n",
    "    gcv.fit(X_train_p, y_train_p)\n",
    "    best[k]=gcv.best_estimator_\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "dd38f199-b421-4074-aeb1-a13ee7925d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0da29d77a85943aba2c4b89fc2bd04c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_dict = {}\n",
    "for k in tqdm(best):\n",
    "    with open(f'sklearn-pkl/polarity/{k}.pkl','wb') as f:\n",
    "        pickle.dump(best[k],f)\n",
    "    y_pred_p = best[k].predict(X_test_p)\n",
    "    score_dict[k]={\n",
    "        'accuracy':accuracy_score(y_pred_p,y_test_p),\n",
    "        'precision':precision_score(y_pred_p,y_test_p),\n",
    "        'recall':recall_score(y_pred_p,y_test_p),\n",
    "        'f1':f1_score(y_pred_p,y_test_p),\n",
    "        'Details':str(best[k])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "7ed32da2-d891-4b9c-918f-6ae4966192ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.804511</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=45)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_regression</th>\n",
       "      <td>0.849624</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.835821</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>LogisticRegression(penalty='none')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.766917</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.720721</td>\n",
       "      <td>RandomForestClassifier(n_estimators=18)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.737705</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>DecisionTreeClassifier(criterion='entropy', sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rbf_svc</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.907407</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>SVC(C=10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_svc</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>SVC(C=10, kernel='linear')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.804511</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>MultinomialNB(alpha=0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.774436</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>AdaBoostClassifier(learning_rate=0.1, n_estima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>linear_discriminant</th>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.645161</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>LinearDiscriminantAnalysis()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quadratic_discriminant</th>\n",
       "      <td>0.511278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>QuadraticDiscriminantAnalysis(reg_param=0.001)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_network</th>\n",
       "      <td>0.87218</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.870229</td>\n",
       "      <td>MLPClassifier(alpha=0.1, max_iter=2000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        accuracy precision    recall        f1  \\\n",
       "knn                     0.804511  0.738462  0.842105  0.786885   \n",
       "logistic_regression     0.849624  0.861538  0.835821  0.848485   \n",
       "random_forest           0.766917  0.615385  0.869565  0.720721   \n",
       "decision_tree           0.729323  0.692308  0.737705  0.714286   \n",
       "rbf_svc                 0.842105  0.753846  0.907407  0.823529   \n",
       "linear_svc              0.842105  0.861538  0.823529  0.842105   \n",
       "naive_bayes             0.804511  0.769231  0.819672  0.793651   \n",
       "adaboost                0.774436  0.753846  0.777778  0.765625   \n",
       "linear_discriminant     0.578947  0.307692  0.645161  0.416667   \n",
       "quadratic_discriminant  0.511278       0.0       0.0       0.0   \n",
       "neural_network           0.87218  0.876923  0.863636  0.870229   \n",
       "\n",
       "                                                                  Details  \n",
       "knn                                  KNeighborsClassifier(n_neighbors=45)  \n",
       "logistic_regression                    LogisticRegression(penalty='none')  \n",
       "random_forest                     RandomForestClassifier(n_estimators=18)  \n",
       "decision_tree           DecisionTreeClassifier(criterion='entropy', sp...  \n",
       "rbf_svc                                                         SVC(C=10)  \n",
       "linear_svc                                     SVC(C=10, kernel='linear')  \n",
       "naive_bayes                                      MultinomialNB(alpha=0.1)  \n",
       "adaboost                AdaBoostClassifier(learning_rate=0.1, n_estima...  \n",
       "linear_discriminant                          LinearDiscriminantAnalysis()  \n",
       "quadratic_discriminant     QuadraticDiscriminantAnalysis(reg_param=0.001)  \n",
       "neural_network                    MLPClassifier(alpha=0.1, max_iter=2000)  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity_result = pd.DataFrame(score_dict).T\n",
    "polarity_result.to_csv('polarity_result.csv')\n",
    "polarity_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fee99d7-7b8d-4c3c-ba7f-2ee4e3dbb711",
   "metadata": {},
   "source": [
    "## 3. Ensemble classiﬁcation\n",
    "for Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "93388ed3-252e-4131-a014-23bdc979d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "estimators = list(best.items())\n",
    "clf = StackingClassifier(\n",
    "    estimators=estimators, final_estimator=LogisticRegression()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "00d53a1f-2f5f-4a75-a8e3-21ff5c7fe4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test = X_train.toarray(),X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "339613a2-5379-423e-b086-0d9f016f85fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StackingClassifier(estimators=[('knn', KNeighborsClassifier(n_neighbors=45)),\n",
       "                               ('logistic_regression',\n",
       "                                LogisticRegression(penalty='none')),\n",
       "                               ('random_forest',\n",
       "                                RandomForestClassifier(n_estimators=18)),\n",
       "                               ('decision_tree',\n",
       "                                DecisionTreeClassifier(criterion='entropy',\n",
       "                                                       splitter='random')),\n",
       "                               ('rbf_svc', SVC(C=10)),\n",
       "                               ('linear_svc', SVC(C=10, kernel='linear')),\n",
       "                               ('naive_bayes', MultinomialNB(alpha=0.1)),\n",
       "                               ('adaboost',\n",
       "                                AdaBoostClassifier(learning_rate=0.1,\n",
       "                                                   n_estimators=100)),\n",
       "                               ('linear_discriminant',\n",
       "                                LinearDiscriminantAnalysis()),\n",
       "                               ('quadratic_discriminant',\n",
       "                                QuadraticDiscriminantAnalysis(reg_param=0.001)),\n",
       "                               ('neural_network',\n",
       "                                MLPClassifier(alpha=0.1, max_iter=2000))],\n",
       "                   final_estimator=LogisticRegression())"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "d36cd17a-8ed4-411c-9924-e590086ef9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.8421052631578947\n",
      "recall:  0.8142857142857143\n",
      "precision:  0.8769230769230769\n",
      "f1:  0.8444444444444444\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred,y_test)\n",
    "recall = recall_score(y_pred,y_test)\n",
    "precision = precision_score(y_pred,y_test)\n",
    "f1 = f1_score(y_pred,y_test)\n",
    "print('accuracy: ',accuracy)\n",
    "print('recall: ',recall)\n",
    "print('precision: ',precision)\n",
    "print('f1: ',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63721a83-3e67-4ed4-b077-93a6631ab67a",
   "metadata": {},
   "source": [
    "## 4. Multitask classiﬁcation\n",
    "classify subjectivity and polarity at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "211d528a-1864-4082-b573-78991827ea5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df1.stemmed\n",
    "label = df1.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "2e3522ad-21bc-45e4-ab78-f0cec6604ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "tf=TfidfVectorizer()\n",
    "text_tf= tf.fit_transform(text)\n",
    "X_train, X_test, y_train, y_test = train_test_split(text_tf, label, test_size=0.2, random_state=114514)\n",
    "X_train, X_test = X_train.toarray(), X_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "88633bec-d403-40cb-a03d-75ea04939e54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('tf-pkl/multi_task.pkl','wb') as f:\n",
    "    pickle.dump(tf,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "ea06ab30-ed8a-44a6-9a5f-4eb6ad0eaa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "logistic = LogisticRegression()\n",
    "rfc = RandomForestClassifier(n_estimators=10)\n",
    "dtc = tree.DecisionTreeClassifier()\n",
    "rbf_svc = SVC(C=0.125)\n",
    "lin_svc = SVC(kernel='linear',C=1)\n",
    "mnb = MultinomialNB(alpha=0.1)\n",
    "abc = AdaBoostClassifier()\n",
    "nn = MLPClassifier(alpha=0.1,max_iter=2000)\n",
    "classifiers = {\n",
    "    'knn':knn,\n",
    "    'logistic_regression':logistic,\n",
    "    'random_forest':rfc,\n",
    "    'decision_tree':dtc,\n",
    "    # 'rbf_svc':rbf_svc,\n",
    "    # 'linear_svc':lin_svc,\n",
    "    'naive_bayes':mnb,\n",
    "    'adaboost':abc,\n",
    "    # 'linear_discriminant':lda,\n",
    "    # 'quadratic_discriminant':qda,\n",
    "    'neural_network':nn\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "aa13c6b3-cd17-4731-bb59-acca0359cda8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7484d60841174b2bb4425414bb9d5d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn\n",
      "logistic_regression\n",
      "random_forest\n",
      "decision_tree\n",
      "naive_bayes\n",
      "adaboost\n",
      "neural_network\n"
     ]
    }
   ],
   "source": [
    "for k in tqdm(classifiers):\n",
    "    classifiers[k]=classifiers[k].fit(X_train,y_train)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "b2fa9cdd-6350-4821-a0a4-6549c75f3633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e2f27f93984977a3b53f64582bf69e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "score_dict = {}\n",
    "for k in tqdm(classifiers):\n",
    "    with open(f'sklearn-pkl/geo/{k}.pkl','wb') as f:\n",
    "        pickle.dump(classifiers[k],f)\n",
    "    y_pred = classifiers[k].predict(X_test)\n",
    "    score_dict[k]={\n",
    "        'accuracy':accuracy_score(y_pred,y_test),\n",
    "        'Details':str(classifiers[k])\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "139ea8a9-0e77-4a39-94f5-d0161d54f63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>Details</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logistic_regression</th>\n",
       "      <td>0.7125</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.679167</td>\n",
       "      <td>RandomForestClassifier(n_estimators=10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.641667</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>naive_bayes</th>\n",
       "      <td>0.745833</td>\n",
       "      <td>MultinomialNB(alpha=0.1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adaboost</th>\n",
       "      <td>0.7125</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neural_network</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>MLPClassifier(alpha=0.1, max_iter=2000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     accuracy                                  Details\n",
       "knn                  0.666667     KNeighborsClassifier(n_neighbors=10)\n",
       "logistic_regression    0.7125                     LogisticRegression()\n",
       "random_forest        0.679167  RandomForestClassifier(n_estimators=10)\n",
       "decision_tree        0.641667                 DecisionTreeClassifier()\n",
       "naive_bayes          0.745833                 MultinomialNB(alpha=0.1)\n",
       "adaboost               0.7125                     AdaBoostClassifier()\n",
       "neural_network       0.766667  MLPClassifier(alpha=0.1, max_iter=2000)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multitask accuracy\n",
    "pd.DataFrame(score_dict).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00506872-f653-4f9f-9777-38bd3da885bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
